# Tiny-Deep-Ensemble
We propose Tiny Deep Ensemble. In our approach, only normalization layers are ensembled $M$ times, with all ensemble members sharing common weights and biases, leading to a significant decrease in storage requirements and latency.
